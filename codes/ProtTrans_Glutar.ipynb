{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agemagician/ProtTrans/blob/master/Embedding/TensorFlow/Advanced/ProtT5-XL-UniRef50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKGoQYFXdGtH"
      },
      "source": [
        "## ProtTrans-Glutar model for glutarylation prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8b7wDufdGtH"
      },
      "outputs": [],
      "source": [
        "#Your input sequence file here in fasta format. The model was trained using peptides of length 23.\n",
        "filename=\"sample.fasta\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b3zlhBHdGtI"
      },
      "source": [
        "### Extracting EAAC dan CTDD protein sequences' features using iFeature toolkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aurU2clJdGtI",
        "outputId": "39a85de5-cf32-4356-a542-1039a2bbab49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Descriptor type: EAAC\n",
            "Descriptor type: CTDD\n"
          ]
        }
      ],
      "source": [
        "!python iFeature.py --file sample.fasta --type EAAC --out EAAC.tsv\n",
        "!python iFeature.py --file sample.fasta --type CTDD --out CTDD.tsv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQcCEtrC6Udr"
      },
      "source": [
        "<h3>Extracting protein sequences' features using ProtT5-XL-UniRef50 pretrained-model</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wCEAM9F5wTA"
      },
      "source": [
        "**1. Load necessry libraries including huggingface transformers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXAKFATm-mbs"
      },
      "outputs": [],
      "source": [
        "!pip install -q SentencePiece transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UhF4ih050mu",
        "outputId": "314aec24-937a-4c83-e5a6-a7b2d21ca43e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-04-25 09:59:47.557553: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2022-04-25 09:59:47.557600: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFT5EncoderModel, T5Tokenizer\n",
        "import numpy as np\n",
        "import re\n",
        "import gc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAKCMu_2-h2V"
      },
      "source": [
        "<b>2. Load the vocabulary and ProtT5-XL-UniRef50 Model<b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HS8i5sOJ-h2W"
      },
      "outputs": [],
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\", do_lower_case=False )\n",
        "#tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_bfd\", do_lower_case=False )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "6039c46157134a998e9e2b1ccec25b63",
            "71af1636b5f840a2a07324812235db10",
            "8b06d496d4704beebea534ddb5ad2330",
            "e699ece0feca440387d082c2b233b58d",
            "b056a2433f154dbaa41f6840015ecf87",
            "19b60494fe2443698785e34808f2027e",
            "7a63fb9f3a2d4fc3b74c85fb7fcbcf9f",
            "039fedc16a9e417c94beea59f5561d1a",
            "1a4ffa8252bb4b5584ad7bdd581cb6da",
            "ebac9c962e824d7794c40ac4d0332b89",
            "982e1e391da849d992f28a7c8ea473fb",
            "5494f8dece5c4a10b5f6af426a760067",
            "d885ef1286954116aabbcdca34303124",
            "8cde50d61e224d50aaffb55ad8323680",
            "04585a7bab58488990342e4081dfdd51",
            "b7dfd3ea823c46a9b65bd8cc7bad793d"
          ]
        },
        "id": "ERtkR05t-h2c",
        "outputId": "4c051838-eb47-430a-a738-3adfecdfd7a5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-04-25 10:00:08.112838: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
            "2022-04-25 10:00:08.112895: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2022-04-25 10:00:08.112932: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (biows1): /proc/driver/nvidia/version does not exist\n",
            "2022-04-25 10:00:08.118531: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-04-25 10:00:08.296264: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFT5EncoderModel: ['decoder.block.12.layer.2.layer_norm.weight', 'decoder.block.21.layer.1.EncDecAttention.q.weight', 'decoder.embed_tokens.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.20.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.block.17.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.14.layer.2.DenseReluDense.wi.weight', 'decoder.block.22.layer.1.EncDecAttention.o.weight', 'decoder.block.16.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.1.EncDecAttention.q.weight', 'decoder.block.9.layer.2.DenseReluDense.wi.weight', 'decoder.block.18.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.12.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.12.layer.0.layer_norm.weight', 'decoder.block.19.layer.1.EncDecAttention.q.weight', 'decoder.block.23.layer.1.EncDecAttention.k.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.23.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.21.layer.1.layer_norm.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.22.layer.2.DenseReluDense.wi.weight', 'decoder.block.19.layer.1.EncDecAttention.k.weight', 'decoder.block.23.layer.1.layer_norm.weight', 'decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.13.layer.0.layer_norm.weight', 'decoder.block.14.layer.1.EncDecAttention.o.weight', 'decoder.block.14.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.11.layer.1.EncDecAttention.q.weight', 'decoder.block.13.layer.1.EncDecAttention.v.weight', 'decoder.block.12.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.12.layer.0.SelfAttention.v.weight', 'decoder.block.11.layer.2.layer_norm.weight', 'decoder.block.21.layer.2.layer_norm.weight', 'decoder.block.12.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.21.layer.0.SelfAttention.v.weight', 'decoder.block.14.layer.1.EncDecAttention.q.weight', 'decoder.block.11.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.20.layer.0.SelfAttention.k.weight', 'decoder.block.16.layer.0.SelfAttention.k.weight', 'decoder.block.13.layer.2.layer_norm.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.10.layer.1.layer_norm.weight', 'decoder.block.7.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.17.layer.2.layer_norm.weight', 'decoder.block.21.layer.2.DenseReluDense.wi.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.19.layer.1.EncDecAttention.o.weight', 'decoder.block.15.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.20.layer.0.SelfAttention.v.weight', 'decoder.block.22.layer.0.SelfAttention.q.weight', 'decoder.block.12.layer.1.EncDecAttention.o.weight', 'decoder.block.23.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.16.layer.0.layer_norm.weight', 'decoder.block.19.layer.2.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.2.DenseReluDense.wi.weight', 'decoder.block.23.layer.0.SelfAttention.v.weight', 'decoder.block.19.layer.0.SelfAttention.q.weight', 'decoder.block.14.layer.0.SelfAttention.k.weight', 'decoder.block.23.layer.0.layer_norm.weight', 'decoder.block.20.layer.0.SelfAttention.q.weight', 'decoder.block.22.layer.1.EncDecAttention.v.weight', 'decoder.block.12.layer.1.EncDecAttention.q.weight', 'decoder.block.16.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.14.layer.0.SelfAttention.v.weight', 'decoder.block.16.layer.1.layer_norm.weight', 'decoder.block.9.layer.1.EncDecAttention.o.weight', 'decoder.block.17.layer.1.layer_norm.weight', 'decoder.block.16.layer.0.SelfAttention.q.weight', 'decoder.block.17.layer.2.DenseReluDense.wi.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.13.layer.0.SelfAttention.v.weight', 'decoder.block.18.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.21.layer.0.SelfAttention.k.weight', 'decoder.block.20.layer.2.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.10.layer.2.DenseReluDense.wi.weight', 'decoder.block.15.layer.0.layer_norm.weight', 'decoder.block.9.layer.0.layer_norm.weight', 'decoder.block.22.layer.0.SelfAttention.v.weight', 'decoder.block.19.layer.1.layer_norm.weight', 'decoder.block.11.layer.0.layer_norm.weight', 'decoder.block.17.layer.1.EncDecAttention.k.weight', 'decoder.block.23.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.1.EncDecAttention.q.weight', 'decoder.block.20.layer.1.layer_norm.weight', 'decoder.block.19.layer.0.SelfAttention.v.weight', 'decoder.block.17.layer.1.EncDecAttention.v.weight', 'decoder.block.12.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.10.layer.1.EncDecAttention.k.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.11.layer.1.EncDecAttention.k.weight', 'decoder.block.14.layer.0.layer_norm.weight', 'decoder.block.15.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.22.layer.0.SelfAttention.o.weight', 'decoder.block.21.layer.1.EncDecAttention.o.weight', 'decoder.block.8.layer.0.SelfAttention.k.weight', 'decoder.block.19.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.21.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.15.layer.1.EncDecAttention.q.weight', 'decoder.block.16.layer.1.EncDecAttention.q.weight', 'decoder.block.14.layer.0.SelfAttention.q.weight', 'decoder.block.13.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.11.layer.1.layer_norm.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.9.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.1.EncDecAttention.q.weight', 'decoder.block.23.layer.2.DenseReluDense.wo.weight', 'decoder.block.15.layer.1.layer_norm.weight', 'decoder.block.18.layer.0.SelfAttention.v.weight', 'decoder.block.21.layer.0.layer_norm.weight', 'decoder.block.17.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.20.layer.2.DenseReluDense.wo.weight', 'decoder.block.17.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.1.EncDecAttention.k.weight', 'decoder.block.13.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.17.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.17.layer.0.layer_norm.weight', 'decoder.block.8.layer.0.layer_norm.weight', 'decoder.block.16.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.11.layer.0.SelfAttention.k.weight', 'decoder.block.19.layer.0.SelfAttention.k.weight', 'decoder.block.16.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.1.layer_norm.weight', 'decoder.block.21.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.23.layer.1.EncDecAttention.o.weight', 'decoder.block.22.layer.1.EncDecAttention.k.weight', 'decoder.block.9.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.14.layer.2.layer_norm.weight', 'decoder.final_layer_norm.weight', 'decoder.block.8.layer.1.EncDecAttention.k.weight', 'decoder.block.13.layer.1.EncDecAttention.q.weight', 'decoder.block.10.layer.0.layer_norm.weight', 'decoder.block.20.layer.0.layer_norm.weight', 'decoder.block.18.layer.2.DenseReluDense.wo.weight', 'encoder.embed_tokens.weight', 'decoder.block.9.layer.0.SelfAttention.k.weight', 'decoder.block.23.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.15.layer.0.SelfAttention.k.weight', 'decoder.block.18.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.15.layer.2.layer_norm.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.16.layer.2.DenseReluDense.wo.weight', 'decoder.block.22.layer.2.layer_norm.weight', 'decoder.block.13.layer.1.EncDecAttention.k.weight', 'decoder.block.12.layer.1.layer_norm.weight', 'decoder.block.13.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.22.layer.1.EncDecAttention.q.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.11.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.19.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.22.layer.0.SelfAttention.k.weight', 'decoder.block.23.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.11.layer.0.SelfAttention.o.weight', 'decoder.block.23.layer.2.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.17.layer.2.DenseReluDense.wo.weight', 'decoder.block.8.layer.2.DenseReluDense.wo.weight', 'decoder.block.14.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.14.layer.1.layer_norm.weight', 'decoder.block.17.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.12.layer.2.DenseReluDense.wi.weight', 'decoder.block.18.layer.1.layer_norm.weight', 'decoder.block.14.layer.1.EncDecAttention.k.weight', 'decoder.block.14.layer.2.DenseReluDense.wo.weight', 'decoder.block.20.layer.1.EncDecAttention.q.weight', 'decoder.block.15.layer.2.DenseReluDense.wo.weight', 'decoder.block.23.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.18.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.18.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.12.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.1.EncDecAttention.o.weight', 'decoder.block.20.layer.1.EncDecAttention.o.weight', 'decoder.block.13.layer.1.EncDecAttention.o.weight', 'decoder.block.20.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.12.layer.0.SelfAttention.o.weight', 'decoder.block.19.layer.0.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.21.layer.1.EncDecAttention.k.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.15.layer.1.EncDecAttention.o.weight', 'decoder.block.15.layer.1.EncDecAttention.v.weight', 'decoder.block.16.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.17.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.19.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.18.layer.2.layer_norm.weight', 'decoder.block.8.layer.2.layer_norm.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.19.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.16.layer.1.EncDecAttention.k.weight', 'decoder.block.22.layer.1.layer_norm.weight', 'decoder.block.21.layer.0.SelfAttention.o.weight', 'decoder.block.13.layer.1.layer_norm.weight', 'decoder.block.13.layer.2.DenseReluDense.wi.weight', 'decoder.block.18.layer.1.EncDecAttention.q.weight', 'decoder.block.13.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.1.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.16.layer.0.SelfAttention.o.weight', 'decoder.block.20.layer.2.DenseReluDense.wi.weight', 'decoder.block.10.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.1.EncDecAttention.o.weight', 'decoder.block.18.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.15.layer.0.SelfAttention.v.weight', 'decoder.block.20.layer.1.EncDecAttention.k.weight', 'decoder.block.18.layer.0.layer_norm.weight', 'decoder.block.15.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.2.layer_norm.weight', 'decoder.block.22.layer.2.DenseReluDense.wo.weight', 'decoder.block.15.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.18.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.11.layer.1.EncDecAttention.v.weight', 'decoder.block.21.layer.1.EncDecAttention.v.weight', 'lm_head.weight', 'decoder.block.8.layer.0.SelfAttention.o.weight', 'decoder.block.22.layer.0.layer_norm.weight']\n",
            "- This IS expected if you are initializing TFT5EncoderModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFT5EncoderModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All the weights of TFT5EncoderModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5EncoderModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "model = TFT5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\", from_pt=True)\n",
        "#model = TFT5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_bfd\", from_pt=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YN6nqLFuY0k2",
        "outputId": "d08b4b48-c046-46be-e080-9aeb6381ceb1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkqAotTcdZnW"
      },
      "source": [
        "<b>3. Create or load sequences and map rarely occured amino acids (U,Z,O,B) to (X)<b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFOBvDwudGtK"
      },
      "outputs": [],
      "source": [
        "protlist = []\n",
        "with open(filename) as fin:\n",
        "    for line in fin:\n",
        "        if line.startswith('>'):\n",
        "            protlist.append(next(fin).strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLozna6RdGtL",
        "outputId": "e4f09584-cbca-4042-b4fd-00f9c04fdf67"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['SLVNELTFSARKMMADEALDSGL',\n",
              " 'PSVSLQTVKLMKEGLEAARLKAY',\n",
              " 'LMDCMNKLKNNKEYLEFRKERSK',\n",
              " 'AATILTSPDLRKQWLQEVKGMAD',\n",
              " 'GLKPEQVERLTKEFSVYMTKDGR',\n",
              " 'GGVEFNIDLPNKKVCIDSEHSSD',\n",
              " 'EQNRTHSASFFKFLTEELSLDQD',\n",
              " 'AFWRELVECFQKISKDSDCRAVV',\n",
              " 'KIFRQQLEVFMKKNVDFLIAEYF',\n",
              " 'GSWGSGLDMHTKPWIRARARKEY']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "protlist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J05zm5wgdGtL"
      },
      "outputs": [],
      "source": [
        "protlist = [\" \".join(sequence) for sequence in protlist]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQ80mgH0dGtL",
        "outputId": "49a49c8e-225b-49d0-fd88-770119a9441d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['S L V N E L T F S A R K M M A D E A L D S G L',\n",
              " 'P S V S L Q T V K L M K E G L E A A R L K A Y',\n",
              " 'L M D C M N K L K N N K E Y L E F R K E R S K',\n",
              " 'A A T I L T S P D L R K Q W L Q E V K G M A D',\n",
              " 'G L K P E Q V E R L T K E F S V Y M T K D G R',\n",
              " 'G G V E F N I D L P N K K V C I D S E H S S D',\n",
              " 'E Q N R T H S A S F F K F L T E E L S L D Q D',\n",
              " 'A F W R E L V E C F Q K I S K D S D C R A V V',\n",
              " 'K I F R Q Q L E V F M K K N V D F L I A E Y F',\n",
              " 'G S W G S G L D M H T K P W I R A R A R K E Y']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "protlist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0zwKinIdZnX"
      },
      "outputs": [],
      "source": [
        "protlist = [re.sub(r\"[UZOB]\", \"X\", sequence) for sequence in protlist]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66BZEB3MdZnf"
      },
      "source": [
        "<b>4. Tokenize, encode sequences and load it into the GPU if possibile<b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xt5uYuu7dZnf"
      },
      "outputs": [],
      "source": [
        "ids = tokenizer.batch_encode_plus(protlist, add_special_tokens=True, padding=True, return_tensors=\"tf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Grl3ieUhdZnj"
      },
      "outputs": [],
      "source": [
        "input_ids = ids['input_ids']\n",
        "attention_mask = ids['attention_mask']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zylf1HyBdZnl"
      },
      "source": [
        "<b>5. Extracting sequences' features and load it into the CPU if needed<b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8CVGPRFdZnm"
      },
      "outputs": [],
      "source": [
        "embedding = model(input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8IsEs35T0T4"
      },
      "outputs": [],
      "source": [
        "embedding = np.asarray(embedding.last_hidden_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Q2AGxlCUrot"
      },
      "outputs": [],
      "source": [
        "attention_mask = np.asarray(attention_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6oeRZ7xdZns"
      },
      "source": [
        "<b>7. Remove padding (\\<pad\\>) and special tokens (\\</s\\>) that is added by ProtT5-XL-UniRef50 model<b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XXoVSPDdZns"
      },
      "outputs": [],
      "source": [
        "features = []\n",
        "for seq_num in range(len(embedding)):\n",
        "    seq_len = (attention_mask[seq_num] == 1).sum()\n",
        "    seq_emd = embedding[seq_num][:seq_len-1]\n",
        "    features.append(seq_emd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiRaUov9eyii",
        "outputId": "c61e9d8d-f352-4f9c-f55d-e8b81e70e27a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[array([[ 0.03629582, -0.25272217, -0.07906041, ...,  0.12213635,\n",
            "         0.09413542,  0.08972404],\n",
            "       [ 0.22051564, -0.262192  , -0.04013605, ...,  0.18325903,\n",
            "         0.23735234,  0.22343889],\n",
            "       [ 0.00964273, -0.04136721, -0.12887119, ..., -0.35683772,\n",
            "        -0.03652622,  0.26135442],\n",
            "       ...,\n",
            "       [ 0.1128105 , -0.01389266, -0.19745976, ...,  0.22488484,\n",
            "        -0.07750582, -0.17140193],\n",
            "       [-0.05688144, -0.09415594, -0.66101795, ..., -0.24926527,\n",
            "        -0.16212186,  0.09775349],\n",
            "       [-0.03187493, -0.0810577 ,  0.08225247, ..., -0.06895956,\n",
            "         0.2325522 , -0.00681481]], dtype=float32), array([[-0.15055022,  0.05364951, -0.01746642, ...,  0.16237238,\n",
            "        -0.03544049,  0.0491399 ],\n",
            "       [ 0.10659074, -0.17598663, -0.31884226, ...,  0.25361112,\n",
            "         0.04247674, -0.01424738],\n",
            "       [ 0.00238571,  0.0408157 ,  0.06145804, ...,  0.25682843,\n",
            "         0.17341541,  0.13685896],\n",
            "       ...,\n",
            "       [ 0.199428  , -0.02964877,  0.15113924, ...,  0.10832237,\n",
            "        -0.20248231, -0.02754082],\n",
            "       [-0.07726149,  0.06466935,  0.07194457, ...,  0.17474988,\n",
            "         0.033119  , -0.11458839],\n",
            "       [-0.047146  ,  0.15007533,  0.14955047, ...,  0.10158359,\n",
            "        -0.17258507, -0.07731763]], dtype=float32), array([[ 0.10549636, -0.02476485, -0.22957665, ...,  0.12635648,\n",
            "         0.13255723, -0.06009826],\n",
            "       [ 0.12963201, -0.19843929, -0.34094766, ...,  0.12429725,\n",
            "        -0.15998574,  0.14867263],\n",
            "       [-0.43561614, -0.18018639, -0.36861497, ...,  0.28116134,\n",
            "        -0.3002428 , -0.08585628],\n",
            "       ...,\n",
            "       [ 0.16208555,  0.06434843,  0.06905364, ..., -0.07178729,\n",
            "        -0.05626723,  0.16405512],\n",
            "       [-0.2363098 ,  0.07626643,  0.07576746, ..., -0.31328028,\n",
            "         0.1841409 , -0.19841093],\n",
            "       [ 0.03378322, -0.02602267,  0.30259043, ..., -0.14131925,\n",
            "        -0.00372915, -0.1876626 ]], dtype=float32), array([[ 0.145043  , -0.04825311, -0.19049591, ...,  0.00466798,\n",
            "         0.15608943, -0.04418033],\n",
            "       [ 0.11916863,  0.05507856, -0.26285928, ...,  0.16273025,\n",
            "        -0.01445365, -0.13268526],\n",
            "       [ 0.18621163, -0.14915894, -0.40288395, ...,  0.07999934,\n",
            "        -0.2295169 , -0.15730917],\n",
            "       ...,\n",
            "       [ 0.21169284,  0.08586722, -0.03441985, ..., -0.0279119 ,\n",
            "         0.06558684,  0.06559   ],\n",
            "       [-0.1910812 , -0.02193013,  0.11479011, ..., -0.00338877,\n",
            "         0.3332974 , -0.14616385],\n",
            "       [-0.05729787,  0.09217741,  0.09646454, ..., -0.09430985,\n",
            "        -0.07674926, -0.10227957]], dtype=float32), array([[-2.12184995e-01, -3.57197136e-01,  2.72826195e-01, ...,\n",
            "         8.67083371e-02, -6.68040290e-02,  1.18812814e-01],\n",
            "       [-2.54060656e-01, -1.43288061e-01, -9.77642834e-02, ...,\n",
            "         2.33940631e-01,  3.34291048e-02,  3.02244902e-01],\n",
            "       [ 1.00133516e-01, -3.89193267e-01,  1.16816796e-02, ...,\n",
            "         3.54984403e-01,  3.01863134e-01, -2.15056930e-02],\n",
            "       ...,\n",
            "       [-1.83339611e-01,  6.01482857e-03,  4.47062492e-01, ...,\n",
            "         1.03383668e-01,  7.70006925e-02,  2.29314208e-01],\n",
            "       [ 4.50021289e-02, -6.47560433e-02,  1.60177737e-01, ...,\n",
            "        -1.22260526e-01, -5.38920693e-04,  1.37122422e-01],\n",
            "       [-5.96337244e-02, -3.06167323e-02,  4.22153696e-02, ...,\n",
            "        -1.59789443e-01,  1.54170096e-02,  7.36140209e-05]], dtype=float32), array([[-3.76941487e-02, -2.81138062e-01, -1.69587359e-01, ...,\n",
            "         2.17727989e-01, -1.06564328e-01,  4.45548929e-02],\n",
            "       [ 4.03786451e-02, -2.54925370e-01, -5.56573689e-01, ...,\n",
            "        -7.30464906e-02, -2.81906009e-01, -1.60883963e-01],\n",
            "       [-2.74360240e-01, -5.16804028e-03, -5.98682240e-02, ...,\n",
            "        -8.61866400e-02, -1.83751315e-01, -1.17791213e-01],\n",
            "       ...,\n",
            "       [ 1.32724494e-01,  1.61400829e-02,  2.77314007e-01, ...,\n",
            "         9.33145061e-02,  1.78449810e-01, -3.74976784e-01],\n",
            "       [-7.92394057e-02,  4.53433916e-02,  3.11859846e-01, ...,\n",
            "        -5.08778468e-02,  5.29135406e-01,  3.03454369e-01],\n",
            "       [ 1.35347322e-01, -1.16686754e-01, -2.44048629e-02, ...,\n",
            "         4.34772955e-04, -5.68552129e-02, -1.18330456e-01]], dtype=float32), array([[ 2.29342625e-01, -2.88756967e-01, -2.08158389e-01, ...,\n",
            "         7.23529384e-02,  6.99915737e-02,  1.17406264e-01],\n",
            "       [ 1.38988748e-01, -1.12122111e-01, -4.02659148e-01, ...,\n",
            "         1.17121488e-01,  1.33266017e-01,  1.55468509e-02],\n",
            "       [-3.09109557e-02, -5.78497611e-02, -4.09416318e-01, ...,\n",
            "        -2.07337714e-03,  3.85934860e-01, -1.25350267e-01],\n",
            "       ...,\n",
            "       [ 6.02821819e-03, -2.26437729e-02,  5.03083095e-02, ...,\n",
            "        -1.41858667e-01,  6.66158050e-02, -8.74733999e-02],\n",
            "       [-3.88765782e-02, -1.50526941e-01, -4.17749323e-02, ...,\n",
            "         6.65205270e-02,  2.36462265e-01,  5.11513762e-02],\n",
            "       [ 7.04101112e-05, -3.72942202e-02,  1.63897336e-01, ...,\n",
            "        -1.01336641e-02,  1.25149498e-02, -1.64687261e-01]], dtype=float32), array([[-0.06836157, -0.4214794 , -0.0884634 , ...,  0.2465432 ,\n",
            "        -0.05733193, -0.13579227],\n",
            "       [-0.05321366,  0.09039742, -0.05251601, ...,  0.21212646,\n",
            "         0.348984  , -0.07352906],\n",
            "       [ 0.09123776,  0.17442247,  0.04824049, ...,  0.16882893,\n",
            "         0.19472647, -0.21530509],\n",
            "       ...,\n",
            "       [ 0.13271898,  0.01914423,  0.15831926, ..., -0.04535195,\n",
            "         0.03720821,  0.10167749],\n",
            "       [ 0.00381819, -0.03082076, -0.12644869, ..., -0.0529083 ,\n",
            "        -0.08125583,  0.1121332 ],\n",
            "       [ 0.16029534, -0.02604624, -0.01856583, ..., -0.20102917,\n",
            "        -0.00359205, -0.13964106]], dtype=float32), array([[-0.18922079, -0.43891886, -0.03054046, ...,  0.18443534,\n",
            "         0.04364976,  0.04314173],\n",
            "       [ 0.0225491 , -0.20729369, -0.09395216, ...,  0.2708265 ,\n",
            "         0.19452913,  0.23187873],\n",
            "       [-0.06006317, -0.03249363,  0.01956479, ..., -0.298057  ,\n",
            "         0.12124219, -0.06100016],\n",
            "       ...,\n",
            "       [-0.11005671, -0.16538607,  0.1062878 , ...,  0.09679655,\n",
            "        -0.38659412,  0.30739653],\n",
            "       [-0.17921197, -0.17589378, -0.30171716, ..., -0.22017996,\n",
            "         0.01623408, -0.03633613],\n",
            "       [ 0.05550363, -0.1747277 , -0.0315728 , ...,  0.01006696,\n",
            "        -0.2689647 ,  0.22391243]], dtype=float32), array([[-1.04780734e-01, -1.11548081e-01, -9.04464647e-02, ...,\n",
            "         7.07201213e-02,  2.13761861e-03,  4.55250032e-02],\n",
            "       [ 2.07114413e-01,  4.60074358e-02, -1.73767507e-01, ...,\n",
            "         1.63637727e-01, -3.78194414e-02, -1.76414877e-01],\n",
            "       [-5.97793348e-02,  1.13811143e-01, -1.31665453e-01, ...,\n",
            "         3.12770218e-01, -2.02239156e-02,  1.34680063e-01],\n",
            "       ...,\n",
            "       [ 3.16418350e-01, -5.51021136e-02,  1.37061462e-01, ...,\n",
            "        -5.44483140e-02, -1.27021670e-01,  3.42119932e-02],\n",
            "       [ 1.23713449e-01,  1.07624471e-01,  1.40438840e-01, ...,\n",
            "         3.13757136e-02, -6.86894506e-02, -3.73142138e-02],\n",
            "       [-7.61541650e-02,  5.80500960e-02,  1.14166506e-01, ...,\n",
            "        -9.80052203e-02,  1.15743838e-04, -1.68626860e-01]], dtype=float32)]\n"
          ]
        }
      ],
      "source": [
        "print(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvMeG-b8dGtM",
        "outputId": "a5aa008f-307c-4ed5-c2b5-b618551baab9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(23, 1024)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6ymgAcCdGtM"
      },
      "source": [
        "**8. Sum features across 23 rows to get the vector**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CL-G4SozdGtM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "sum_features = []\n",
        "for element in features:\n",
        "    sum_features.append(element.sum(axis=0))\n",
        "prott5_xl_uniref50 = pd.DataFrame(sum_features)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fi13slV0dGtN"
      },
      "source": [
        "### Combine all features: CTDD, EAAC, ProtT5-XL-UniRef50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ecBw5oEdGtN"
      },
      "outputs": [],
      "source": [
        "def strip_first_col(fname, delimiter=None):\n",
        "    with open(fname, 'r') as fin:\n",
        "        for line in fin:\n",
        "            try:\n",
        "               yield line.split(delimiter, 1)[1]\n",
        "            except IndexError:\n",
        "               continue\n",
        "\n",
        "ctdd = np.loadtxt(strip_first_col('CTDD.tsv'), delimiter=\"\\t\",skiprows=1)\n",
        "\n",
        "eaac = np.loadtxt(strip_first_col('EAAC.tsv'), delimiter=\"\\t\",skiprows=1)\n",
        "\n",
        "X=np.concatenate((ctdd,prott5_xl_uniref50),axis=1)\n",
        "X=np.concatenate((X,eaac),axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqBKlLNwdGtN"
      },
      "source": [
        "### Load and apply ProtTrans-Glutar model for classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oBib8AydGtN",
        "outputId": "398edd3f-f45f-4953-d41c-2680e8aa0118"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# load model from file, choose either model trained using training data only, or model trained using whole data\n",
        "\n",
        "loaded_model = pickle.load(open(\"ProtTrans-Glutar.train.model\", \"rb\"))\n",
        "#loaded_model = pickle.load(open(\"ProtTrans-Glutar.full.model\", \"rb\"))\n",
        "\n",
        "\n",
        "# make predictions for supplied data\n",
        "y_pred = loaded_model.predict(X)\n",
        "predictions = [round(value) for value in y_pred]\n",
        "\n",
        "print (predictions)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "039fedc16a9e417c94beea59f5561d1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          },
          "model_module_version": "1.2.0"
        },
        "04585a7bab58488990342e4081dfdd51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          },
          "model_module_version": "1.5.0"
        },
        "19b60494fe2443698785e34808f2027e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          },
          "model_module_version": "1.2.0"
        },
        "1a4ffa8252bb4b5584ad7bdd581cb6da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_982e1e391da849d992f28a7c8ea473fb",
              "IPY_MODEL_5494f8dece5c4a10b5f6af426a760067"
            ],
            "layout": "IPY_MODEL_ebac9c962e824d7794c40ac4d0332b89"
          },
          "model_module_version": "1.5.0"
        },
        "5494f8dece5c4a10b5f6af426a760067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7dfd3ea823c46a9b65bd8cc7bad793d",
            "placeholder": "​",
            "style": "IPY_MODEL_04585a7bab58488990342e4081dfdd51",
            "value": " 7.44G/11.3G [03:23&lt;01:35, 40.2MB/s]"
          },
          "model_module_version": "1.5.0"
        },
        "6039c46157134a998e9e2b1ccec25b63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b06d496d4704beebea534ddb5ad2330",
              "IPY_MODEL_e699ece0feca440387d082c2b233b58d"
            ],
            "layout": "IPY_MODEL_71af1636b5f840a2a07324812235db10"
          },
          "model_module_version": "1.5.0"
        },
        "71af1636b5f840a2a07324812235db10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          },
          "model_module_version": "1.2.0"
        },
        "7a63fb9f3a2d4fc3b74c85fb7fcbcf9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          },
          "model_module_version": "1.5.0"
        },
        "8b06d496d4704beebea534ddb5ad2330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19b60494fe2443698785e34808f2027e",
            "max": 546,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b056a2433f154dbaa41f6840015ecf87",
            "value": 546
          },
          "model_module_version": "1.5.0"
        },
        "8cde50d61e224d50aaffb55ad8323680": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          },
          "model_module_version": "1.2.0"
        },
        "982e1e391da849d992f28a7c8ea473fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "Downloading:  38%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cde50d61e224d50aaffb55ad8323680",
            "max": 11275562628,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d885ef1286954116aabbcdca34303124",
            "value": 7441550336
          },
          "model_module_version": "1.5.0"
        },
        "b056a2433f154dbaa41f6840015ecf87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          },
          "model_module_version": "1.5.0"
        },
        "b7dfd3ea823c46a9b65bd8cc7bad793d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          },
          "model_module_version": "1.2.0"
        },
        "d885ef1286954116aabbcdca34303124": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          },
          "model_module_version": "1.5.0"
        },
        "e699ece0feca440387d082c2b233b58d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_039fedc16a9e417c94beea59f5561d1a",
            "placeholder": "​",
            "style": "IPY_MODEL_7a63fb9f3a2d4fc3b74c85fb7fcbcf9f",
            "value": " 546/546 [00:00&lt;00:00, 1.71kB/s]"
          },
          "model_module_version": "1.5.0"
        },
        "ebac9c962e824d7794c40ac4d0332b89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          },
          "model_module_version": "1.2.0"
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}